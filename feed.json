{
    "version": "https://jsonfeed.org/version/1",
    "title": "blogHez",
    "description": "",
    "home_page_url": "https://baronhez.github.io",
    "feed_url": "https://baronhez.github.io/feed.json",
    "user_comment": "",
    "author": {
        "name": "Jonathan Ródenas López"
    },
    "items": [
        {
            "id": "https://baronhez.github.io/how-to-secure-docker/",
            "url": "https://baronhez.github.io/how-to-secure-docker/",
            "title": "How to secure Docker",
            "summary": "Some tips&hellip;",
            "content_html": "\n    <h2 id=\"some-tips-to-have-a-more-secure-experience-while-using-docker\">\n      Some tips to have a more secure experience while using Docker\n    </h2>\n\n  <p>\n    Ok, the other day I was browsing my bookmarks when I came across an interesting post about Docker security. Because of this, I'm going to share some tips for you to secure your Docker. This way, you will feel safer while using Docker to run some dangerous software, preventing access to your host machine.\n  </p>\n\n    <h2 id=\"tip-1-do-not-havenbspoutdated-containers-running-in-your-server\">\n      Tip #1: Do NOT have&nbsp;outdated containers running in your server.\n    </h2>\n\n  <p>\n    This applies too to Docker itself. Using software outdated, even when we use containers, is insecure, and can lead to vulnerabilities. Containers talk directly to the kernel, so a kernel related vulnerability which can allow the user to modify the kernel, can lead us to a disaster.\n  </p>\n\n    <h2 id=\"tip-2nbsp-do-not-expose-the-docker-daemon-socket\">\n      Tip #2:&nbsp; Do NOT expose the Docker daemon socket.\n    </h2>\n\n  <p>\n    \"But, if my containers need to comunicate with other containers...\" Well, do it at your own risk, buddy. I do not encourage anyone to do this. You can do it, but following good security practices, as seen in the <a href=\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-socket-option\" target=\"_blank\" rel=\"nofollow noopener\">Docker Documentation</a>.\n  </p>\n\n    <h2 id=\"tip-3-do-not-run-your-containers-as-root-user\">\n      Tip #3: Do NOT run your containers as root user.\n    </h2>\n\n  <p>\n    Use an unprivileged user, during runtime:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run -u 4000 alpine\n</code></pre>\n\n  <p>\n    Or during build time:\n  </p>\n<pre class=\"line-numbers  language-docker\"><code>FROM alpine\nRUN groupadd -r myuser && useradd -r -g myuser myuser\n&lt;HERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.&gt;\nUSER myuser\n</code></pre>\n\n  <p>\n    You should also <a href=\"https://docs.docker.com/engine/security/userns-remap/#enable-userns-remap-on-the-daemon\" target=\"_blank\" rel=\"nofollow noopener\">enable namespace support</a>.\n  </p>\n\n    <h2 id=\"tip-4-do-not-run-containers-with-all-capabilities\">\n      Tip #4: Do NOT run containers with all capabilities.\n    </h2>\n\n  <p>\n    For those who don't know what <a href=\"https://man7.org/linux/man-pages/man7/capabilities.7.html\" target=\"_blank\" rel=\"nofollow noopener\">capabilities</a>&nbsp;are, they are a set of privileges.&nbsp;Docker, by default, runs with only a subset of capabilities. But, you can drop some capabilities (using <b>--cap-drop</b>) to harden your docker containers, or add some capabilities (using <b>--cap-add</b>) if needed. Remember not to run containers with the <b>--privileged flag</b>&nbsp;(this will add ALL Linux kernel capabilities to the container).\n<br>\n<br>The most secure setup is to drop all capabilities<b> --cap-drop</b> all and then add only required ones:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --cap-drop all --cap-add CHOWN alpine</code></pre>\n\n    <h2 id=\"tip-5-do-not-let-any-container-to-escalate-privileges\">\n      Tip #5: Do NOT let any container to escalate privileges.\n    </h2>\n\n  <p>\n    Always run your docker images with <b>--security-opt=no-new-privileges</b> in order to prevent escalate privileges using setuid or setgid binaries:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --security-opt=no-new-privileges alpine</code></pre>\n\n    <h2 id=\"tip-6-do-not-allow-your-containers-to-communicate-between-them\">\n      Tip #6: Do NOT allow your containers to communicate between them.\n    </h2>\n\n  <p>\n    By default inter-container communication (<b>icc</b>) is enabled - it means that all containers can talk with each other (using docker0 bridged network). This can be disabled by running docker daemon with --icc=false flag.\n  </p>\n\n  <p>\n    If icc is disabled (icc=false) it is required to tell which containers can communicate using <b>--link=CONTAINER_NAME&nbsp;</b>or <b>ID:ALIAS </b>option:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --link=web alpine</code></pre>\n\n    <h2 id=\"tip-7-do-not-forget-about-using-a-good-security-module\">\n      Tip #7: Do NOT forget about using a good security module.\n    </h2>\n\n  <p>\n    I have seen information about&nbsp;<a href=\"https://docs.docker.com/engine/security/seccomp/\" target=\"_blank\" rel=\"nofollow noopener\">seccomp </a>or <a href=\"https://docs.docker.com/engine/security/apparmor/\" target=\"_blank\" rel=\"nofollow noopener\">AppArmor</a>. This will help you to protect yourself againts vulnerability.\n  </p>\n\n    <h2 id=\"tip-8-do-not-allow-your-containers-to-use-as-much-cpu-and-memory-as-they-can-set-limits\">\n      Tip #8: Do NOT allow your containers to use as much CPU and memory as they can. Set limits.\n    </h2>\n\n  <p>\n    You can limit memory, CPU, maximum number of restarts (--restart=on-failure:&lt;number of restarts&gt;<number_of_restarts>), maximum number of file descriptors (--ulimit nofile=&lt;number&gt;<number>) and maximum number of processes (--ulimit nproc=&lt;number&gt;<number>).</number></number></number_of_restarts>\n  </p>\n\n  <p>\n    Refer to the <a href=\"https://docs.docker.com/engine/reference/commandline/run/#set-ulimits-in-container---ulimit\" target=\"_blank\" rel=\"nofollow noopener\">documentation</a> for more information about ulimits, or to this <a href=\"https://docs.docker.com/config/containers/resource_constraints/\" target=\"_blank\" rel=\"nofollow noopener\">documentation </a>about memory and cpu limits during runtime.\n  </p>\n\n    <h2 id=\"tip-9-do-not-allow-your-containers-to-write-to-your-file-system-if-possible\">\n      Tip #9: Do NOT allow your containers to write to your file system if possible.\n    </h2>\n\n  <p>\n    If you can, use read-only&nbsp;using <b>--read-only</b> flag. For instance:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --read-only alpine sh -c 'echo \"whatever\" &gt; /tmp'</code></pre>\n\n  <p>\n    If an application inside a container has to save something temporarily, combine <b>--read-only</b> flag with<b> --tmpfs</b> like this:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --read-only --tmpfs /tmp alpine sh -c 'echo \"whatever\" &gt; /tmp/file'\n</code></pre>\n\n  <p>\n    In Docker-Compose would be something like:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>version: \"3\"\nservices:\n  alpine:\n    image: alpine\n    read_only: true\n</code></pre>\n\n  <p>\n    It is possible to do it with volumes:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>web:\n    container_name: web\n    image: nginx\n    volumes:\n      - /home/user/nginx/html:/usr/share/nginx/html:ro\n</code></pre>\n\n  <p>\n    This option is also available in runtime:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run -v volume-name:/path/in/container:ro alpine</code></pre>\n\n  <p>\n    You can do this using the<b> --mount</b> option:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker run --mount source=volume-name,destination=/path/in/container,readonly alpine</code></pre>\n\n    <h2 id=\"tip-10-do-not-forget-aboutnbspstatic-analysis-tools\">\n      Tip #10: Do NOT forget about&nbsp;static analysis tools.\n    </h2>\n\n  <p>\n    There are a few useful tools that can help you in various ways.&nbsp;This list is from that article I previously mentioned above:\n  </p>\n\n    <h4 id=\"to-scan-your-containers-in-search-of-vulnerabilitiesnbsp\">\n      To scan your containers in search of vulnerabilities:&nbsp;\n    </h4>\n\n    <h5 id=\"free\">\n      Free\n    </h5>\n\n  <ul>\n    <li><a href=\"https://github.com/coreos/clair\" target=\"_blank\" rel=\"nofollow noopener\">Clair</a></li><li><a href=\"https://github.com/deepfence/ThreatMapper\" target=\"_blank\" rel=\"nofollow noopener\">ThreatMapper</a><br></li><li><a href=\"https://github.com/knqyf263/trivy\" target=\"_blank\" rel=\"nofollow noopener\" class=\"\">Trivy</a></li>\n  </ul>\n\n    <h5 id=\"commercial\">\n      Commercial\n    </h5>\n\n  <ul>\n    <li><a href=\"https://snyk.io/\" target=\"_blank\" rel=\"nofollow noopener\">Snyk</a>&nbsp;<b>(open source and free option available)</b></li><li><a href=\"https://anchore.com/opensource/\" target=\"_blank\" rel=\"nofollow noopener\">anchore</a>&nbsp;<b>(open source and free option available)</b><br></li><li><a href=\"https://jfrog.com/xray/\" target=\"_blank\" rel=\"nofollow noopener\">JFrog XRay</a><br></li><li><a href=\"https://www.qualys.com/apps/container-security/\" target=\"_blank\" rel=\"nofollow noopener\">Qualys</a><br></li>\n  </ul>\n\n    <h4 id=\"to-detect-secrets-in-images\">\n      To detect secrets in images:\n    </h4>\n\n  <ul>\n    <li><a href=\"https://github.com/GitGuardian/ggshield\" target=\"_blank\" rel=\"nofollow noopener\">ggshield</a>&nbsp;<b>(open source and free option available)</b></li><li><a href=\"https://github.com/deepfence/SecretScanner\" target=\"_blank\" rel=\"nofollow noopener\">SecretScanner&nbsp;</a>&nbsp;<b>(open source)</b></li>\n  </ul>\n\n    <h4 id=\"to-detect-misconfigurations-in-docker\">\n      To detect misconfigurations in Docker:\n    </h4>\n\n  <ul>\n    <li><a href=\"https://www.inspec.io/docs/reference/resources/docker/\" target=\"_blank\" rel=\"nofollow noopener\">inspec.io</a></li><li><a href=\"https://dev-sec.io/baselines/docker/\" target=\"_blank\" rel=\"nofollow noopener\">dev-sec.io</a><br></li><li><a href=\"https://github.com/docker/docker-bench-security\" target=\"_blank\" rel=\"nofollow noopener\">Docker Bench for Security</a></li>\n  </ul>\n\n    <h2 id=\"tip-11-do-not-forget-about-logs\">\n      Tip #11: Do NOT forget about logs.\n    </h2>\n\n  <p>\n    Set up an appropriate log level, you'll thank me later. Countless time I've been safe by logs. You should configure the Docker daemon to log events that you would want to review later:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker-compose --log-level info up  </code></pre>\n\n    <h2 id=\"tip-12-do-not-forget-about-linting-your-dockerfiles-during-build-time\">\n      Tip #12: Do NOT forget about linting your Dockerfiles during build time.\n    </h2>\n\n  <p>\n    It is as easy as following a few good practices:\n  </p>\n\n  <ul>\n    <li>Ensure a <b>USER </b>directive is specified.</li><li>Ensure the base image version is pinned.<br></li><li>Ensure the OS packages versions are pinned.<br></li><li>Avoid the use of <b>ADD </b>in favor of <b>COPY</b>.<br></li><li>Avoid curl bashing in <b>RUN </b>directives.</li>\n  </ul>\n\n  <p>\n    Aaaaaand that's it, folks. Following this tips, you should be safer while using Docker. Have a nice day, friend.\n  </p>\n\n    <h2 id=\"credits\">\n      Credits\n    </h2>\n\n  <p>\n    <a href=\"https://cheatsheetseries.owasp.org/cheatsheets/Docker_Security_Cheat_Sheet.html\" target=\"_blank\" rel=\"nofollow noopener\">https://cheatsheetseries.owasp.org/cheatsheets/Docker_Security_Cheat_Sheet.html</a>\n  </p>",
            "image": "https://baronhez.github.io/media/posts/18/dockerSec.jpeg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Security",
                   "Docker-compose",
                   "Docker"
            ],
            "date_published": "2022-09-03T22:28:37+02:00",
            "date_modified": "2022-09-03T22:28:37+02:00"
        },
        {
            "id": "https://baronhez.github.io/how-to-convert-different-files-online/",
            "url": "https://baronhez.github.io/how-to-convert-different-files-online/",
            "title": "How to convert different files online",
            "summary": "A curate&hellip;",
            "content_html": "\n    <h2 id=\"a-curate-selection-of-online-converters\" class=\"align-center\">\n      A curate selection of online converters.\n    </h2>\n\n  <p>\n    Image to ascii converter: <a href=\"https://github.com/TheZoraiz/ascii-image-converter\" target=\"_blank\" rel=\"nofollow noopener\">https://github.com/TheZoraiz/ascii-image-converter</a>\n  </p>\n\n  <p>\n    Video To Lottie Converter:&nbsp;<a href=\"https://isotropic.co/tool/video-to-lottie\" target=\"_blank\" rel=\"nofollow noopener\">https://isotropic.co/tool/video-to-lottie</a>\n  </p>\n\n  <p>\n    Multi-file converters:\n  </p>\n\n  <ul>\n    <li><a href=\"https://www.aconvert.com/\" target=\"_blank\" rel=\"nofollow noopener\">https://www.aconvert.com</a></li><li><a href=\"https://www.online-convert.com/es\" target=\"_blank\" rel=\"nofollow noopener\">https://www.online-convert.com/es</a><br></li><li><a href=\"https://convertio.co/\" target=\"_blank\" rel=\"nofollow noopener\">https://convertio.co/</a><br></li><li><a href=\"https://www.ilovepdf.com/\" target=\"_blank\" rel=\"nofollow noopener\">https://www.ilovepdf.com/</a><br></li><li><a href=\"https://tinywow.com/\" target=\"_blank\" rel=\"nofollow noopener\">https://tinywow.com/</a><br></li><li><a href=\"https://cloudconvert.com/\" target=\"_blank\">https://cloudconvert.com/</a><br></li><li><a href=\"https://www.onlineocr.net/\" target=\"_blank\" rel=\"nofollow noopener\">https://www.onlineocr.net/</a><br></li>\n  </ul>",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Interesting Webpages"
            ],
            "date_published": "2022-09-03T00:04:14+02:00",
            "date_modified": "2022-09-03T00:04:14+02:00"
        },
        {
            "id": "https://baronhez.github.io/how-to-clean-your-docker/",
            "url": "https://baronhez.github.io/how-to-clean-your-docker/",
            "title": "How to clean your Docker.",
            "summary": "I'm not&hellip;",
            "content_html": "\n    <h2 id=\"im-not-joking-do-it-you-will-thank-me-later\" class=\"align-center\">\n      I'm not joking, do it, you will thank me later.\n    </h2>\n\n  <p>\n    The faster way of doing this is using the CLI. I explained how to do it in my <a href=\"https://baronhez.github.io/b/\" target=\"_blank\">Self-Hosting guide</a>, but I'm going to sum it up here.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># We can delete all stoped container, every network not use by al least one container, all dangling images and all dangling build cache.\ndocker system prune\n# We can delete all stoped container, every network not use by al least one container, every unused image and all build cache.\ndocker system prune -a\n# Do the same but filtering specific images\ndocker system prune --filter nginx:alpine\n# Or just the volumes\ndocker system prune --volumes # First way\ndocker volume prune # Second way\n# Or just the networks\ndocker volume prune\n# Or we can do the same but without asking for confirmation\ndocker system prune -a -f  </code></pre>\n\n  <p>\n    That's it, nice and fast.\n  </p>\n\n    <h2 id=\"credits\">\n      Credits\n    </h2>\n\n  <p>\n    <a href=\"https://wise.wtf/posts/docker-cleaning/\" target=\"_blank\">https://wise.wtf/posts/docker-cleaning/</a>\n  </p>",
            "image": "https://baronhez.github.io/media/posts/16/woman-collects-leaves-cleans-park.jpg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Docker"
            ],
            "date_published": "2022-08-31T04:20:22+02:00",
            "date_modified": "2022-08-31T04:20:22+02:00"
        },
        {
            "id": "https://baronhez.github.io/different-uses-for-docker/",
            "url": "https://baronhez.github.io/different-uses-for-docker/",
            "title": "Different uses for Docker",
            "summary": "A month&hellip;",
            "content_html": "\n  <p>\n    A month ago, I read a post in <a href=\"https://matt-rickard.com/non-obvious-docker-uses\" target=\"_blank\" rel=\"nofollow noopener\">Matt Rickard blog</a>&nbsp;about Docker uses barely known among Docker users. So here I am, sharing that knowledge with you, wise reader.\n  </p>\n\n    <h2 id=\"you-can-use-docker-as-a-compiler\">\n      You can use Docker as a compiler.\n    </h2>\n\n  <p>\n    <a href=\"https://docs.docker.com/engine/reference/commandline/build/#custom-build-outputs\" target=\"_blank\" rel=\"nofollow noopener\">Here</a> is the official documentation about this use case.&nbsp;\n  </p>\n\n  <p>\n    Instead of exporting the build artifacts as a Docker image, you can do it as files on the local filesystem, which can be helpful for producing local binaries, code generation, etc.\n  </p>\n\n  <p>\n    For example, we can use docker to export the artifact to a tar file:\n  </p>\n\n  <p>\n    \n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker build --output type=local,dest=out .</code></pre>\n\n  <p>\n    Feel free to visit the documentation for further information.\n  </p>\n\n    <h2 id=\"you-can-use-docker-build-a-taskrunner-alternative-tonbspimakei\">\n      You can use Docker build a task-runner alternative to&nbsp;<i>make.</i>\n    </h2>\n\n  <p>\n    Matt points in his post that, thanks to Docker Buildkit,&nbsp;you can write alternative frontends to build images, not only Dockerfiles. This functionality is described <a href=\"https://matt-rickard.com/building-a-new-dockerfile-frontend\" target=\"_blank\" rel=\"nofollow noopener\">here</a>.\n  </p>\n\n    <h2 id=\"you-can-use-docker-registry-to-store-tarballs\">\n      You can use Docker registry to store tarballs.\n    </h2>\n\n  <p>\n    Because docker registries only store tarballs and metadata, it is easy to set up a place to store configuration.\n  </p>\n\n    <h2 id=\"you-can-use-git-repositories-as-docker-images\">\n      You can use git repositories as Docker images\n    </h2>\n\n  <p>\n    Matt points this possibility in this <a href=\"https://matt-rickard.com/docker-merge/\" target=\"_blank\" rel=\"nofollow noopener\">post</a>. To sum it up, \"Docker merge is a CLI utility that provides a proof-of-concept strategy to merge docker images\".\n  </p>\n\n  <p>\n    So, you can use that tool to&nbsp;to hijack the \"git merge\" strategies to natively \"merge\" docker layers.\n  </p>\n\n    <h2 id=\"you-can-use-docker-a-crossplatform-compatibility-layer\">\n      You can use Docker a cross-platform compatibility layer.\n    </h2>\n\n  <p>\n    The most obvious case for this is the use of Docker Desktop (if you are using this in your company, use Rancher instead).\n  </p>\n\n    <h2 id=\"you-can-use-docker-to-build-linux-kernels\">\n      You can use Docker to build Linux kernels\n    </h2>\n\n  <p>\n    You can do it by using <a href=\"https://github.com/linuxkit/linuxkit\" target=\"_blank\" rel=\"nofollow noopener\">LinuxKit</a>.\n  </p>\n\n  <p>\n    Those where the examples mentioned in the post, I hope you find them useful!\n  </p>\n\n    <h2 id=\"credits\">\n      Credits\n    </h2>\n\n  <p>\n    <a href=\"https://matt-rickard.com/\" target=\"_blank\" rel=\"nofollow noopener\">Matt Rickard</a>\n  </p>",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Docker"
            ],
            "date_published": "2022-08-31T04:10:08+02:00",
            "date_modified": "2022-08-31T04:20:30+02:00"
        },
        {
            "id": "https://baronhez.github.io/docker-compose-best-practices/",
            "url": "https://baronhez.github.io/docker-compose-best-practices/",
            "title": "Docker-Compose Best Practices",
            "summary": "Or \"The&hellip;",
            "content_html": "\n    <h2 id=\"or-the-best-way-to-use-dockercompose-pick-your-poison-\">\n      Or \"The best way to use Docker-Compose\", pick your poison. \n    </h2>\n\n  <p>\n    Ok, I get it. You want to use Docker-Compose in your working environment, but you don't want to destroy everything in the process, and at the same time, get the most out of it.\n  </p>\n\n  <p>\n    Here you go, 6 easy-to-follow tips for you, fellow DevOps!\n  </p>\n\n    <h2 id=\"tip-1-do-not-rebuild-your-image-each-time-you-make-a-change-in-code-use-volumes-instead\">\n      Tip #1: Do NOT rebuild your image each time you make a change in code, use volumes instead.\n    </h2>\n\n  <p>\n    One of my best friends was having a hard time a few months ago, because every time he had to change a line in his python program, he had to rebuild the docker image, and then deploy that new image to the server (what 0 CI/CD pipelines do to a man, hehe).\n  </p>\n\n  <p>\n    The answer to that problem was to use volumes from the beginning. If you, wise reader, save the code in a directory and then, when building the image, use that directory as the volume, the only thing you will have to do to apply the changes made to the code is to restart the container. \n  </p>\n\n  <p>\n    The most easy-to-see example is a nginx image. Save your .html page in a directory, mount that directory as a volume, like:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code> volumes:\n      - /home/example/index.html:/usr/share/nginx/html:ro</code></pre>\n\n  <p>\n    And then, build and deploy that image as a container.\n  </p>\n\n  <p>\n    If you want to make a change to your web page, change the index.html file and then restart the container. You will see the changes immediately.&nbsp;\n  </p>\n\n    <h2 id=\"tip-2-be-smart-do-not-write-the-same-file-two-times-for-dev-and-prod\">\n      Tip #2: Be smart, do NOT write the same file two times for dev and prod.\n    </h2>\n\n  <p>\n    Ok, assuming that you are developing and application, and you need to use some kind of <a href=\"https://webpack.js.org/\" target=\"_blank\" rel=\"nofollow noopener\">Webpack</a> or a PostgresDB ONLY in the dev environment... well, you can use the same docker-compose.yml file and the same .env file, but making a lot of changes each time you have to deploy to prod... On the other hand, that's annoying and awful, so, let's use an override file!\n  </p>\n\n  <p>\n    But what is an override file and why is it so useful in this case?\n  </p>\n\n  <p>\n    Well, imagine that you have a file like this one:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code># docker-compose.yml\nweb:\n  image: example/my_web_app:latest\n  depends_on:\n    - db\n    - cache\n\ndb:\n  image: postgres:latest\n\ncache:\n  image: redis:latest\n</code></pre>\n\n  <p>\n    If you, for testing purposes, want to deploy this application while exposing some ports, mount your code as a volume, and build the web image, then you should use this override file:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code># docker-compose.override.yml\nweb:\n  build: .\n  volumes:\n    - '.:/code'\n  ports:\n    - 8883:80\n  environment:\n    DEBUG: 'true'\n\ndb:\n  command: '-d'\n  ports:\n    - 5432:5432\n\ncache:\n  ports:\n    - 6379:6379\n</code></pre>\n\n  <p>\n    Then, while having both files in the same directory, run:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker-compose up</code></pre>\n\n  <p>\n    Now, watch in amazement as the services of both archives are deployed at the same time. The reason is that docker-compose search in the current directory for a file named <b>docker-compose.yml</b> or <b>docker-compose.yaml</b>. Then, search for a file name <b>docker-compose.override.yml</b>. Finally, deploys the services contained in both files.\n  </p>\n\n  <p>\n    This is really useful, because if you want to not expose those ports in prod, it is as simple as renaming the override file with any other name. By doing this, we will be deploying only the services in the <b>docker-compose.yml </b>file.&nbsp;\n  </p>\n\n  <p>\n    You can use this in many ways. For instance, you can have a docker-compose.override.example.yml which you can change and rename as <b>docker-compose.override.yml</b>&nbsp;everytime you need to test something in dev. It is similar to when we use a <b>.env-example</b> file. In the <b>.env-example</b> file we have some default or null values which we can change when creating a <b>.env </b>file.\n  </p>\n\n  <p>\n    Another use for the override file is when we are deploying an application in some cloud provider, such as AWS or GCP, which provides some service, as postgres management. If we want to use our own postgres in dev environment, we can use an <b>docker-compose-override.yml </b>file with the postgres service, while in prod, we only use the <b>docker-compose.yml</b>.\n  </p>\n\n  <p>\n    Another way to get modularity is to use the command line:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code># service.yml\nservices:\n  service:\n    image: my-image:latest</code></pre>\n<pre class=\"line-numbers  language-yaml\"><code># service-dev.yml\nservices:\n  service:\n    environment:\n      - DEV_MODE=true</code></pre>\n<pre class=\"line-numbers  language-bash\"><code>docker-compose -f service.yml -f service-dev.yml up -d</code></pre>\n\n    <h5 id=\"credits-for-this-part\">\n      Credits for this part:\n    </h5>\n\n  <p>\n    <a href=\"https://www.youtube.com/watch?v=jGePPQFArwo\" target=\"_blank\" rel=\"nofollow noopener\">https://www.youtube.com/watch?v=jGePPQFArwo</a>\n  </p>\n\n  <p>\n    <a href=\"https://docs.docker.com/compose/extends/\" target=\"_blank\" rel=\"nofollow noopener\">https://docs.docker.com/compose/extends/</a>\n  </p>\n\n  <p>\n    <a href=\"https://www.howtogeek.com/devops/how-to-simplify-docker-compose-files-with-yaml-anchors-and-extensions/\" target=\"_blank\" rel=\"nofollow noopener\">https://www.howtogeek.com/devops/how-to-simplify-docker-compose-files-with-yaml-anchors-and-extensions/</a>\n  </p>\n\n    <h2 id=\"tip-3-be-lazy-do-not-rewrite-the-same-yaml-parts-over-and-over\">\n      Tip #3: Be lazy, do NOT rewrite the same yaml parts over and over.\n    </h2>\n\n  <p>\n    Use YAML Archors&nbsp;for your yaml files if you are using over and over again the same yaml names or steps.\n  </p>\n\n  <p>\n    There are 2 parts to this:\n  </p>\n\n  <ul>\n    <li>The anchor '&amp;' which defines a chunk of configuration.<br></li><li>The alias '*' used to refer to that chunk elsewhere.<br></li>\n  </ul>\n<pre class=\"line-numbers  language-yaml\"><code>services:\n  httpd:\n    image: httpd:latest\n    restart: &restartpolicy unless-stopped\n  mysql:\n    image: mysql:latest\n    restart: *restartpolicy</code></pre>\n\n  <p>\n    You can reuse multiple lines:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>services:\n  first:\n    image: my-image:latest\n    environment: &env\n      - CONFIG_KEY\n      - EXAMPLE_KEY\n      - DEMO_VAR\n  second:\n    image: another-image:latest\n    environment: *env</code></pre>\n\n  <p>\n    Or even extend those chunks of configuration:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>services:\n  image: my-image:latest\n    environment: &env\n      - CONFIG_KEY\n      - EXAMPLE_KEY\n      - DEMO_VAR      \n  second:\n    image: another-image:latest\n    environment:\n      &lt;&lt;: *env\n      - AN_EXTRA_KEY\n      - SECOND_SPECIFIC_KEY  </code></pre>\n\n  <p>\n    You can use Yaml Archors with Extension fields, because yaml&nbsp;parser will ignore extension fields prefixed with x-. This way, you can reuse, as I mentioned before, chunks of configuration to share configuration:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>x-env: &env\n  environment:\n    - CONFIG_KEY\n    - EXAMPLE_KEY\n \nservices:\n  first:\n    &lt;&lt;: *env\n    image: my-image:latest\n  second:\n    &lt;&lt;: *env\n    image: another-image:latest  </code></pre>\n\n  <p class=\"msg msg--warning\">\n    YAML anchors and aliases cannot contain the ' [ ', ' ] ', ' { ', ' } ', and ' , ' characters.\n  </p>\n\n  <p>\n    Here is a <a href=\"https://www.howtogeek.com/devops/how-to-simplify-docker-compose-files-with-yaml-anchors-and-extensions/\" target=\"_blank\" rel=\"nofollow noopener\" class=\"\" data-link-popup-id=\"1661906797091\">guide</a>, which is the one I used to write this tip.\n  </p>\n\n    <h2 id=\"tip-4-do-not-forget-to-refresh-environment-variables\">\n      Tip #4: Do NOT forget to refresh environment variables.\n    </h2>\n\n  <p>\n    Set the restart behavior to <u>restart: always</u>&nbsp;and configure your services with update_config: true. This way, your environment variables will be refreshed each run.\n  </p>\n\n    <h2 id=\"tip-5-do-not-use-docker-rm-f-when-cleaning-up-docker-images\">\n      Tip #5: Do NOT use \"docker rm -f\" when cleaning up docker images.\n    </h2>\n\n  <p>\n    Use this instead:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker rm -f --remove-orphans</code></pre>\n\n  <p>\n    Regardless of whether we or a running container utilizes them, the \"--remove-ophans\" flag guarantees that Docker Compose only removes containers and images that are no longer in use.\n  </p>\n\n    <h2 id=\"tip-6-do-not-let-your-containers-consume-as-much-memory-and-cpu-as-they-want\">\n      Tip #6: Do NOT let your containers consume as much memory and CPU as they want.\n    </h2>\n\n  <p>\n    Although it may seem unusual and silly, you shouldn't allow any container use all the resources it needs.\n  </p>\n\n  <p>\n    You can do this by setting limits:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code># docker-compose.yml\nweb:\n  deploy:\n    resources:\n      limits:\n        cpus: \"1\"\n</code></pre>\n\n  <p class=\"msg msg--highlight\">\n    Before setting these limits, you should know how many resources your services may need to function properly.\n  </p>\n\n  <p>\n    And those were the best practices I wanted to share with you, fellow DevOps folks. I hope you find them useful.\n  </p>\n\n    <h2 id=\"credits\">\n      Credits\n    </h2>\n\n  <p>\n    <a href=\"https://prod.releasehub.com/blog/6-docker-compose-best-practices-for-dev-and-prod\" target=\"_blank\" rel=\"nofollow noopener\">https://prod.releasehub.com/blog/6-docker-compose-best-practices-for-dev-and-prod</a>\n  </p>",
            "image": "https://baronhez.github.io/media/posts/14/Docker-Logo-2.png",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Docker-compose",
                   "Docker"
            ],
            "date_published": "2022-08-31T03:23:43+02:00",
            "date_modified": "2022-08-31T03:24:15+02:00"
        },
        {
            "id": "https://baronhez.github.io/how-to-get-a-free-vps-in-oracle-cloud/",
            "url": "https://baronhez.github.io/how-to-get-a-free-vps-in-oracle-cloud/",
            "title": "How to get a free VPS in Oracle Cloud",
            "summary": "How to&hellip;",
            "content_html": "\n  <p>\n    How to get a free VPS in Oracle Cloud with 4 cores, 24 GB of memory and 200 GB of capacity.\n  </p>\n\n  <p>\n    I'll describe how to set up a free virtual server using Oracle Cloud in this post; you may choose to use these machines to test web applications that require a lot more power than shared hosting, or even to mount your own server, to deploy services using docker or Kubernetes.&nbsp;\n  </p>\n\n  <p>\n    First, you will need to create an account at <a href=\"https://www.oracle.com/cloud/sign-in.html\" target=\"_blank\" rel=\"nofollow noopener\">https://www.oracle.com/cloud/sign-in.html</a> with an email address and bank card number (don't worry, it's just to check if your account is real, this is still free, they will charge you around 1$ and then they will give it back to you).\n  </p>\n\n  <p>\n    You must enter the administration console and select the option \"Create a VM instance\":\n  </p>\n\n    <figure class=\"post__image post__image--full\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/oracle.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/oracle-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/oracle-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/oracle-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/oracle-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/oracle-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/oracle-2xl.PNG 1600w\"  height=\"510\" width=\"1264\" alt=\"\" />\n      <figcaption>Pick that one.</figcaption>\n    </figure>\n\n  <p>\n    Set the instance name next:\n  </p>\n\n    <figure class=\"post__image post__image--wide\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/instance-2.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/instance-2-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/instance-2-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/instance-2-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/instance-2-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/instance-2-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/instance-2-2xl.PNG 1600w\"  height=\"174\" width=\"901\" alt=\"\" />\n      \n    </figure>\n\n  <p>\n    Now, placement:\n  </p>\n\n    <figure class=\"post__image post__image--wide\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/instance-3.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/instance-3-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/instance-3-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/instance-3-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/instance-3-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/instance-3-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/instance-3-2xl.PNG 1600w\"  height=\"145\" width=\"1081\" alt=\"\" />\n      <figcaption>Leave it as it is</figcaption>\n    </figure>\n\n  <p>\n    The following part is important:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-2xl.PNG 1600w\"  height=\"281\" width=\"1642\" alt=\"\" />\n      <figcaption>Click in \"Change image\"</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-2.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-2-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-2-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-2-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-2-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-2-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-2-2xl.PNG 1600w\"  height=\"114\" width=\"367\" alt=\"\" />\n      <figcaption>Select \"Canonical Ubuntu\"</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-3.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-3-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-3-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-3-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-3-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-3-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-3-2xl.PNG 1600w\"  height=\"61\" width=\"224\" alt=\"\" />\n      <figcaption>Click on \"Select image\" at the bottom of the screen.</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-5.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-5-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-5-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-5-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-5-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-5-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-5-2xl.PNG 1600w\"  height=\"180\" width=\"1625\" alt=\"\" />\n      <figcaption>Click on \"Change shape\"</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-4.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-4-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-4-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-4-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-4-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-4-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-4-2xl.PNG 1600w\"  height=\"137\" width=\"1654\" alt=\"\" />\n      <figcaption>Click on \"Ampere\" option</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-6.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-6-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-6-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-6-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-6-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-6-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-6-2xl.PNG 1600w\"  height=\"233\" width=\"1584\" alt=\"\" />\n      <figcaption>Set it to the maximum \"4 cores, 24 GB memory\"</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-7.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-7-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-7-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-7-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-7-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-7-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-7-2xl.PNG 1600w\"  height=\"55\" width=\"216\" alt=\"\" />\n      <figcaption>Then, once again, click on \"Select shape\"</figcaption>\n    </figure>\n\n  <p>\n    Now, generate a SSH key pair. If you do not know how to do it, go to <a href=\"https://baronhez.github.io/how-to-configure-ssh-to-be-secure/\" target=\"_blank\">my post about SSH</a> and learn how to do it.\n  </p>\n\n  <p>\n    Once you have your SSH key pair fresh, regardless of the operating system you are using, check this option and upload your public key:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-8.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-8-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-8-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-8-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-8-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-8-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-8-2xl.PNG 1600w\"  height=\"236\" width=\"956\" alt=\"\" />\n      <figcaption>Click on \"Upload public key files (.pub)\"</figcaption>\n    </figure>\n\n  <p>\n    Location of your SSH keys in different OS:\n  </p>\n\n  <ul>\n    <li><b>Windows:</b> Should be in <i>%userprofile%\\.shh</i></li><li><b>Linux:</b>&nbsp;<i>~/.ssh&nbsp;</i></li><li><b>MacOS:</b>&nbsp;<i>~/.ssh</i>&nbsp;</li>\n  </ul>\n\n  <p>\n    Upload the file named <b>id_rsa.pub</b> (this is the default name, if you haven't changed it).\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-9.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-9-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-9-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-9-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-9-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-9-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-9-2xl.PNG 1600w\"  height=\"140\" width=\"749\" alt=\"\" />\n      <figcaption>Click on \"Specify a custom boot volume size\" and then set that to 200 GB.</figcaption>\n    </figure>\n\n  <p>\n    Once the instance configuration is finished, you should see something like this:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-10.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-10-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-10-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-10-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-10-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-10-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-10-2xl.PNG 1600w\"  height=\"318\" width=\"701\" alt=\"\" />\n      <figcaption>Now that your instance is up and running, it is time to connect via SSH.</figcaption>\n    </figure>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/13/1-12.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/13/responsive/1-12-xs.PNG 300w ,https://baronhez.github.io/media/posts/13/responsive/1-12-sm.PNG 480w ,https://baronhez.github.io/media/posts/13/responsive/1-12-md.PNG 768w ,https://baronhez.github.io/media/posts/13/responsive/1-12-lg.PNG 1024w ,https://baronhez.github.io/media/posts/13/responsive/1-12-xl.PNG 1360w ,https://baronhez.github.io/media/posts/13/responsive/1-12-2xl.PNG 1600w\"  height=\"109\" width=\"320\" alt=\"\" />\n      <figcaption>Use your public IP to connect to your server.</figcaption>\n    </figure>\n\n  <p>\n    If you don't know how to use SSH:\n  </p>\n\n  <p>\n    <b>On Linux and MacOS</b>, you should use open-ssh (it is pre-installed in most cases).\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>ssh ubuntu@&lt;your-ip&gt;</code></pre>\n\n  <p>\n    On Windows, use Powershell (Powershell has open-ssh pre-installed, or at least that's the case on my machine. Use something like <a href=\"https://www.siteground.com/tutorials/ssh/putty/\" target=\"_blank\" rel=\"nofollow noopener\">Putty</a> if you get lost following this step).\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>ssh ubuntu@&lt;your-ip&gt; # same as Linux and MacOS</code></pre>\n\n  <p>\n    And that's it, folks! Now you have a free vps with 4 cores, 24 GB of memory, 200 GB of capacity in like 5 minutes more or less. Ease peasy.\n  </p>",
            "image": "https://baronhez.github.io/media/posts/13/oracle-cloud.png",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Self-hosted"
            ],
            "date_published": "2022-08-31T00:59:24+02:00",
            "date_modified": "2022-08-31T01:25:26+02:00"
        },
        {
            "id": "https://baronhez.github.io/b/",
            "url": "https://baronhez.github.io/b/",
            "title": "Self-Hosting Guide",
            "summary": "I know,&hellip;",
            "content_html": "\n  <p>\n    I know, you want to self host, for instance, your own webpage, but every time you search for info, people only recommend you to use sh*t like NO-IP and third party providers such as Heroku. But that's not what you want, right? You have a Rashberry Pi or some old PC and you intent to host your own services, like your webpage, a torrent server or even some filebrowser to manage storage.\n  </p>\n\n  <p>\n    Ok, then I will save you a lot of hours or researching how to mount everything, how to deal with nginx, how to get https certificates... and I will show you the best way of setting up everything.\n  </p>\n\n    <h2 id=\"prepare-your-server-machine\">\n      Prepare your server machine\n    </h2>\n\n  <p>\n    Firtsly, I will start by getting an ISO of Ubuntu Server (you can use another ISOs, like arch linux or Nix, if you are brave enough).&nbsp;\n  </p>\n\n  <p>\n    <a href=\"https://releases.ubuntu.com/22.04.1/ubuntu-22.04.1-live-server-amd64.iso\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">https://releases.ubuntu.com/22.04.1/ubuntu-22.04.1-live-server-amd64.iso</a>\n  </p>\n\n  <p>\n    Then, use some program, like <a href=\"https://github.com/pbatard/rufus/releases/download/v3.17/rufus-3.17.exe\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">Rufus</a> or <a href=\"https://www.balena.io/etcher/\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">Balena Etcher</a> to flash that ISO into an USB or SD Card (in case you're using a Rashberry Pi).\n  </p>\n\n  <p>\n    If you are not familiar with this, take a look into <a href=\"https://www.youtube.com/watch?v=Wt0Q-DBejIw\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">this tutorial</a>.\n  </p>\n\n  <p>\n    Ok, now we have an USB or SD Card flashed with our favourite OS for our server. Now it is time to insert that into the server we will be using. If it's possible I recommend you to connect that device to a monitor, in order to see what is happening and make some SSH configurations.\n  </p>\n\n  <p>\n    Once the operating system is installed, we will create a new user and get rid of the default user. (Using the root user for everything is a bad idea).\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo adduser Username\nsudo usermod -aG sudo Username\n</code></pre>\n\n    <h2 id=\"how-to-connect-to-our-machine\">\n      How to connect to our machine\n    </h2>\n\n  <p>\n    Next, we will configure SSH to be able to connect to our device from another pc. This way it is easier to manage the server (and we will be able to disconnect the monitor from the server).\n  </p>\n\n  <p>\n    I have another guide about how configure SSH to be secure and ready to use, go ahead a <a href=\"https://baronhez.github.io/how-to-configure-ssh-to-be-secure/\" target=\"_blank\" class=\"\">check it</a>.\n  </p>\n\n    <h2 id=\"unattended-upgrades-optional\">\n      Unattended upgrades (optional)\n    </h2>\n\n  <p class=\"msg msg--highlight\">\n    If you don't want automated updates, skip this section.\n  </p>\n\n  <p>\n    Ok, now that we are able to connect to the server using SSH, and SSH is configure to be secure, it is time to install our first packages.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt install unattended-upgrades\ndpkg-reconfigure --priority=low unattended-upgrades\n# Now, select yes to enable unattended-upgrades.\n# Once you finish with that, you can change some lines in the configuration of unattended-upgrades.\nnano /etc/apt/apt.conf.d/10periodic\n</code></pre>\n\n  <p>\n    For instance, you can configure something like this:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>APT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Download-Upgradeable-Packages \"1\";\nAPT::Periodic::AutocleanInterval \"7\";\nAPT::Periodic::Unattended-Upgrade \"1\";</code></pre>\n\n    <h2 id=\"email-your-logs-to-yourself-optional\">\n      Email your logs to yourself (optional)\n    </h2>\n\n  <p class=\"msg msg--highlight\">\n    If you don't want to email your logs, skip this section.\n  </p>\n\n  <p>\n    If you want to keep track of your logs and email them to you, then you can use <a href=\"https://linux.die.net/man/8/logwatch\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">Logwatch</a>.\n  </p>\n\n  <p>\n    To install and configure logwatch, run these commands:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt-get install logwatch\nnano /etc/cron.daily/00logwatch</code></pre>\n\n  <p>\n    Then, add this line:\n  </p>\n<pre class=\"line-numbers  language-html\"><code>/usr/sbin/logwatch --output mail --mailto yourmail@gmail.com --detail high  </code></pre>\n\n    <h2 id=\"installation-of-docker-and-dockercompose\">\n      Installation of Docker and Docker-Compose\n    </h2>\n\n  <p class=\"msg msg--info\">\n    The rest of the guide focuses on using docker and docker-compose to deploy services. If you want to deploy your services manually by configuring nginx and cert-manager, go ahead and try it yourself. If you want to do it using kubernetes, I will publish a guide as soon as possible.\n  </p>\n\n  <p>\n    It's time to install docker and docker compose:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt update && sudo apt upgrade\nsudo apt install apt-transport-https ca-certificates curl software-properties-common  \ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"  \napt-cache policy docker-ce\nsudo apt install docker-ce\nsudo systemctl status docker\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose  \nsudo chmod +x /usr/local/bin/docker-compose\n</code></pre>\n\n  <p>\n    Now,&nbsp;assuming that everything went well, we should have docker and docker-compose installed in our server.&nbsp; It's time to test docker-compose by deploying a small web in our local network.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>mkdir app\nnano app/index.html\n</code></pre>\n\n  <p>\n    Insert this content into the <b>index.html</b> file:\n  </p>\n<pre class=\"line-numbers  language-html\"><code>&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;title&gt;Docker Compose Demo&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/kognise/water.css@latest/dist/dark.min.css\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n\t&lt;h1&gt;This is a Docker Compose Demo Page.&lt;/h1&gt;\n\t&lt;p&gt;This content is being served by an Nginx container.&lt;/p&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;</code></pre>\n\n  <p>\n    Save the file, and run the following command:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>nano docker-compose.yml</code></pre>\n\n  <p>\n    Insert this content into the <b>docker-compose.yml</b> file:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code>version: '3.7'\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"8000:80\"\n    volumes:\n      - ./app:/usr/share/nginx/html</code></pre>\n\n  <p>\n    Now, to start our aplication&nbsp;containerized, we must run the following command:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>docker-compose up -d\n</code></pre>\n\n  <p>\n    That command should return an output like this one:\n  </p>\n<pre class=\"line-numbers  language-html\"><code>Creating network \"compose-demo_default\" with the default driver\nPulling web (nginx:alpine)...\nalpine: Pulling from library/nginx\ncbdbe7a5bc2a: Pull complete\n10c113fb0c77: Pull complete\n9ba64393807b: Pull complete\nc829a9c40ab2: Pull complete\n61d685417b2f: Pull complete\nDigest: sha256:57254039c6313fe8c53f1acbf15657ec9616a813397b74b063e32443427c5502\nStatus: Downloaded newer image for nginx:alpine\nCreating compose-demo_web_1 ... done</code></pre>\n\n  <p>\n    Now, your webpage should be accesible through your browser by typing \"local-IP-of-your-server:8000\".\n  </p>\n\n  <p>\n    Ok, now that we have a webpage deployed in our local network, I should share a few useful commands to manage Docker:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># We can see the logs of our containers\ndocker-compose logs\n# Pause our containers\ndocker-compose pause\n# Unpause our containers\ndocker-compose unpause\n# Stop our containers\ndocker-compose stop\n# Delete all the resources and volumes assigned to our containers\ndocker-compose down\n# List our images\ndocker images\n# Delete our images\ndocker image rm nginx:alpine\n# Or\ndocker rmi nginx:alpine\n# We can delete all stoped container, every network not use by al least one container, every unused image and all build cache.\ndocker system prune -a\n# Do the same but filtering specific images\ndocker system prune --filter nginx:alpine\n# Or just the volumes\ndocker system prune --volumes\n# Or we can do the same but without asking for confirmation\ndocker system prune -a -f  \n</code></pre>\n\n  <p>\n    Now, if you want to deploy you web to the world outside your local network, you must change a few things in your router (supposing you have access to the router). It is completely necessary to set port-forwarding, because if you are mounting your server at home, your devices are connected inside your home using a private network. It is possible for us to connect to the internet thanks to <a href=\"https://en.wikipedia.org/wiki/Network_address_translation\" rel=\"nofollow noopener\">NAT</a>.&nbsp;\n  </p>\n\n  <p>\n    Each router is a different world, so you must search information about how to port-forward in your home router.&nbsp;\n  </p>\n\n  <p>\n    On the other hand, if you're using some provider for your server, such as a VM in Oracle Cloud, then it should be easier. Search for your specific provider how to port-forward and that's the end of the problem.\n  </p>\n\n    <h2 id=\"using-a-domain-name-and-ddns\">\n      Using a domain name and DDNS\n    </h2>\n\n  <p>\n    Ok, if you want to access your webpage easily without having to memorize a bunch of numbers, you have to buy a domain name. I recommend&nbsp;<a href=\"https://www.namecheap.com/\" target=\"_blank\" class=\"\" data-link-popup-id=\"1661636146747\">https://www.namecheap.com/</a>. It provides cheap domain names and it is also a DNS provider, but you can pick whichever you want.\n  </p>\n\n  <p>\n    If you want to point your domain name to your server, there is one problem if your server is in your home. Most ISPs (or all of them, to be honest) nowadays change your public IP from time to time. If you don't want to lose access to your webpage when that happens, we must use Dynamic DNS. It is necessary to set DDNS with your DNS provider and use a DDNS client in our server to comunicate with our DNS provider. The DDNS client will inform the DNS provider of your new IP.\n  </p>\n\n  <p>\n    I use <a href=\"https://ddclient.net/\" target=\"_blank\" rel=\"nofollow noopener\">ddclient</a> for that, because Namecheap has a <a href=\"https://www.namecheap.com/support/knowledgebase/article.aspx/583/11/how-do-i-configure-ddclient/\" target=\"_blank\" rel=\"nofollow noopener\">guide</a> to use it with them.\n  </p>\n\n    <h2 id=\"using-https-certificates-from-lets-encrypt\">\n      Using HTTPS certificates from Let's Encrypt\n    </h2>\n\n  <p>\n    Next step is to create HTTPS certificates for our webpage. The docker way of doing this is by configurating let's encrypt. We can do it using different methods, but the best for me is using one of the best&nbsp;Edge Router nowadays. I'm talking of <a href=\"https://doc.traefik.io/traefik/\" target=\"_blank\" rel=\"nofollow noopener\"><u>Traefik</u></a>.\n  </p>\n\n  <p>\n    I will save you tons of documentation, because this guide is already too long. If you want to set a reverse proxy with traefik which also can generate certificates with Let's Encrypt, just use this files:\n  </p>\n\n  <p>\n    First, create an acme.json file and change its privilegies (take into account the path of the acme.json file, because you have to add that path to the <b>docker-compose.yaml</b> file:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>touch acme.json\nchmod 600 acme.json</code></pre>\n\n  <p>\n    Now, create a folder and two different files for traefik configuration (put your domain name where it says YOUR-DOMAIN-NAME and your preferred email where it says youremail@example.com):\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>mkdir ./config\nnano ./config/traefik.yml</code></pre>\n<pre class=\"line-numbers  language-yaml\"><code># traefik.yml\napi:\n  dashboard: true # Enable the dashboard\nentryPoints:\n  web:\n    address: \":80\"\n    http:\n      redirections:\n        entryPoint:\n          to: web-secure\n  web-secure:\n    address: \":443\"\n    http:\n      tls:\n        certResolver: default\nproviders:\n        # In order to get this working on docker, refer to https://doc.traefik.io/traefik/providers/docker/ for more info.\n  docker:\n    endpoint: \"unix:///var/run/docker.sock\"\n    exposedByDefault: false # As seen in the documentation, \"Expose containers by default through Traefik. If set to false, containers that do not have a traefik.enable=true label are ignored from the resulting routing configuration\".\n  file:\n    filename: /etc/traefik/config.yml # In order to get all my configuration info in a separate file (dinamic.yaml), I use https://doc.traefik.io/traefik/providers/file/.\n    watch: true # Watch for changes\n    \ncertificatesResolvers: # Refer to https://doc.traefik.io/traefik/https/acme/#certificate-resolvers to more info. \n  default:\n    acme:\n      email: youremail@example.com \n      storage: /etc/traefik/acme/acme.json # Previously you have to create the file, change the permissions using chmod and then use a docker volume.\n      keyType: 'EC384' # \n      tlsChallenge: true # https://doc.traefik.io/traefik/https/acme/#tlschallenge\n</code></pre>\n\n  <p>\n    Now, we have to configure one last yaml file&nbsp;(put your domain name where it says YOUR-DOMAIN-NAME):\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>nano ./config/config.yml</code></pre>\n<pre class=\"line-numbers  language-yaml\"><code># config.yml\nhttp:\n  routers:\n    traefik:\n      rule: Host(`subdomainForTheDashboard.YOUR-DOMAIN-NAME`)\n      entryPoints: \n        - \"web-secure\"\n      service: api@internal\n      middlewares:\n        - secHeader\n      tls:\n        certResolver: default\n  middlewares:\n          # In order to modify the request, I use middlewares. In this case to force https.\n    secHeader:\n        # HSTS / Secure Headers, Useful to have a more secure experience with HTTPS\n      headers:\n        accessControlMaxAge: \n          - 100\n        hostsProxyHeaders:\n          - \"X-Forwarded-Host\"\n        forceSTSHeader: true\n        frameDeny: true\n        sslRedirect: true\n        browserXssFilter: true      \n        contentTypeNosniff: true\n        customFrameOptionsValue: \"allow-from https:YOUR-DOMAIN-NAME\"\n        referrerPolicy: \"same-origin\"\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 31536000\n        featurePolicy: \"camera 'none'; geolocation 'none'; microphone 'none'; payment 'none'; usb 'none'; vr 'none';\"\n        customResponseHeaders:\n          X-Robots-Tag: \"none,noarchive,nosnippet,notranslate,noimageindex,\"\n          server: \"YOUR-DOMAIN-NAME\"\ntls:\n        # Now, I refer to https://doc.traefik.io/traefik/https/tls/ for information. \n        # Options allow me to to configure some parameters of the TLS connection.\n  options:\n    default:\n            # Now, here a use the min Version tls version 1.2 just as shown in the traefik documentation (This config will get an A+ grade in https://www.ssllabs.com/ssltest/) \n      minVersion: VersionTLS12 # Refering to the Traefik Documentation, I use sniStrict because \"Traefik won't allow connections from clients that do not specify a server_name extension or don't match any certificate configured on the tlsOption\".\n      sniStrict: true\n      cipherSuites:\n        - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n        - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\n        - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\n        - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384   # TLS 1.2\n        - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305    # TLS 1.2\n        - TLS_AES_256_GCM_SHA384                  # TLS 1.3\n        - TLS_CHACHA20_POLY1305_SHA256            # TLS 1.3\n        # Now I define the eliptic curves preferences for ECC cryptography\n        # Refer to https://pkg.go.dev/crypto/tls#CurveID for more info\n      curvePreferences:\n        - CurveP521\n        - CurveP384\n    mintls13:\n      minVersion: VersionTLS13\n      sniStrict: true\n</code></pre>\n\n  <p>\n    Ok, this configuration should work flawlessly. You can add more middlewares, such as rate limit or plugins like fail2ban. I'm not covering that here right now.\n  </p>\n\n  <p>\n    Lastly, a <b>docker-compose.yaml</b>(put your domain name where it says YOUR-DOMAIN-NAME and put the path to your acme.json file and your webpage folder):\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>nano docker-compose.yaml</code></pre>\n<pre class=\"line-numbers  language-yaml\"><code>version: '3.7'\nservices:\n  traefik:\n    image: traefik:2.5.5\n    container_name: traefik\n    network_mode: host\n    restart: unless-stopped\n    volumes:\n      - ./config/:/etc/traefik/\n      - /path/to/acme.json:/etc/traefik/acme/acme.json\n      - /var/run/docker.sock:/var/run/docker.sock\n  web:\n    image: nginx:1.21.4-alpine\n    container_name: web\n    restart: always\n    expose:\n      - \"80\"\n    volumes:\n      - /path/to/your/webpage/folder:/usr/share/nginx/html:ro\n    labels:\n      - traefik.enable=true\n      - traefik.http.routers.webpage.entryPoints=web-secure\n      - traefik.http.routers.webpage.rule=Host(`YOUR-DOMAIN-NAME`)\n      - \"traefik.http.routers.webpage.middlewares=secHeader@file\"\n</code></pre>\n\n  <p>\n    If you want to deploy more services, just add this to every new service in a docker-compose file:\n  </p>\n<pre class=\"line-numbers  language-yaml\"><code> labels:\n      - traefik.enable=true\n      - traefik.http.routers.NAME-ROUTER.entryPoints=web-secure\n      - traefik.http.routers.NAME-ROUTER.rule=Host(`YOUR-DOMAIN-NAME`)\n      - \"traefik.http.routers.NAME-ROUTER.middlewares=secHeader@file\"</code></pre>\n\n  <p>\n    Just remember to change NAME-ROUTER to another name each time (it is the name of the <a href=\"https://doc.traefik.io/traefik/routing/routers/\" rel=\"nofollow noopener\" class=\"\" target=\"_blank\">traefik router</a>) and YOUR-DOMAIN-NAME should be a subdomain, such as <b>nextcloud.example.com</b>&nbsp;for a hipothetical nextcloud service.\n  </p>\n\n  <p>\n    To deploy this configuration, go to the folder where the <b>docker-compose.yaml</b> file is, and run the following command:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo docker-compose up -d</code></pre>\n\n  <p>\n    If you go to your domain, assuming that you previouly pointed the domain to your server IP (or the public IP of your router, in case of a home server), the webpage should be displayed in the browser as intended.\n  </p>\n\n  <p>\n    That's it, you have started in the selfhosting hobby. I recommend you this <a href=\"https://www.reddit.com/r/selfhosted/\" rel=\"nofollow noopener\">subreddit</a>.\n  </p>\n\n  <p>\n    Good luck, lads.\n  </p>",
            "image": "https://baronhez.github.io/media/posts/11/young-man-engineer-making-program-analyses.jpg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Self-hosted",
                   "SSH",
                   "Docker"
            ],
            "date_published": "2022-08-28T02:48:46+02:00",
            "date_modified": "2022-09-03T00:04:34+02:00"
        },
        {
            "id": "https://baronhez.github.io/how-to-get-notifications-each-time-someone-enters-your-server/",
            "url": "https://baronhez.github.io/how-to-get-notifications-each-time-someone-enters-your-server/",
            "title": "How to get notifications each time someone enters your server",
            "summary": "Get a&hellip;",
            "content_html": "\n    <h1 id=\"get-a-notification-on-telegram-or-slack\" class=\"align-center\">\n      Get a notification on Telegram or Slack\n    </h1>\n\n    <h2 id=\"telegram-notificationnbsp\">\n      Telegram notification&nbsp;\n    </h2>\n\n  <p>\n    Firstly, create a telegram bot. To create one, you need to contact the BotFather, which is essentially a bot used to create other bots.\n<br>\n<br>The command you need is /newbot which leads to the following steps to create your bot:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/12/telegr.png\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/12/responsive/telegr-xs.png 300w ,https://baronhez.github.io/media/posts/12/responsive/telegr-sm.png 480w ,https://baronhez.github.io/media/posts/12/responsive/telegr-md.png 768w ,https://baronhez.github.io/media/posts/12/responsive/telegr-lg.png 1024w ,https://baronhez.github.io/media/posts/12/responsive/telegr-xl.png 1360w ,https://baronhez.github.io/media/posts/12/responsive/telegr-2xl.png 1600w\"  height=\"858\" width=\"860\" alt=\"\" />\n      <figcaption>Setting a bot is as simple as this.</figcaption>\n    </figure>\n\n  <p>\n    The next step is to setup a group where you want your alerts to go and add yourself, the bot you just created and <a href=\"https://t.me/myidbot\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">IDbot</a>.\n  </p>\n\n  <p>\n    IDBot will give you the CHATID. You can do this by sending \"<i>/getgroupid\"&nbsp;</i>into the group. It'll return the group ID for the channel, simply prepend a hyphen to the number and that's the chatID: <i>-123456789</i> as an example. Grab this, plus the HTTP API  key of your own bot, and add them to the following script:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># Login Notifications\nCHATID=CHANGEME\nBOTKEY=CHANGEME\n\n# get hostname\nHOSTNM=$( hostname )\n\n# get external IP address\nIP=$( curl -s http://whatismyip.akamai.com/ )\n\n# find IP address of person last logged in\nLOGININFO=$( last -1 -i | head -n 1)\n\n# parse into nice format\nLOGININFO1=$( python3 -c \"login='$LOGININFO'.split('   '); del login[1]; del login[1]; print(''.join([x.strip(' ') + '   \\n' for x in login]));\" )\n\n# send information to telegram notification bot\ncurl -X POST -H 'Content-Type: application/json' -d \"{\\\"chat_id\\\": \\\"$CHATID\\\", \\\"text\\\": \\\"Log in to: $HOSTNM\\n$IP\\nfrom: $LOGININFO1\\\", \\\"disable_notification\\\": false}\" https://api.telegram.org/bot$BOTKEY/sendMessage --silent &gt; /dev/null</code></pre>\n\n  <p>\n    This can then either be bundled into a bash script and called from your profile or written straight into the profile:\n  </p>\n\n  <ul>\n    <li>If your shell is ZSH:&nbsp;</li>\n  </ul>\n<pre class=\"line-numbers  language-bash\"><code>nano /etc/zsh/zprofile</code></pre>\n\n  <ul>\n    <li>If your shell is Bash:</li>\n  </ul>\n<pre class=\"line-numbers  language-bash\"><code>  nano /etc/profile</code></pre>\n\n    <h2 id=\"slack-notification\">\n      Slack notification\n    </h2>\n\n  <p>\n    You will need a Slack webhook. <a href=\"https://api.slack.com/messaging/webhooks\" target=\"_blank\" class=\"\" rel=\"nofollow noopener\">Here</a> is the documentation about creating one.\n  </p>\n\n  <p>\n    After getting a webhook, you should have a URL like this one:\n  </p>\n<div> https://hooks.slack.com/services/VALUE1/VALUE2</div>\n\n  <p>\n    To get a Slack notification I will use a python script.&nbsp;For this reason, you need to: install python, install the Slack SDK and write the script.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt update\nsudo apt install python3\npip install slack_sdk    \nnano notification.py</code></pre>\n\n  <p>\n    The content of <b>notification.py</b> must be the following:\n  </p>\n<pre class=\"line-numbers  language-python\"><code>from slack_sdk.webhook import WebhookClient\nimport os\n\nurl = \" https://hooks.slack.com/services/VALUE1/VALUE2\"\nwebhook = WebhookClient(url)\nHOSTNM = os.popen('hostname').read()\nIP = os.popen('curl -s http://whatismyip.akamai.com/').read()\nLOGININFO=os.popen('last -1 -i | head -n 1 | cut -d \" \" -f 1').read()\n\nresponse = webhook.send(text='Log in to: {}\\n from {}\\n by\\n User: {} \\n'.format(HOSTNM,IP,LOGININFO))\nassert response.status_code == 200\nassert response.body == \"ok\"</code></pre>\n\n  <p>\n    Save the changes, then run the script just for testing purposes:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>python3 /path/to/the/file/notification.py</code></pre>\n\n  <p>\n    Then, after checking that the script runs flawlessly, add the command at the end of your profile, the same way you would add the telegram bash script to your profile, depending of the shell you're using.\n  </p>\n\n  <p>\n    And that's it, now you should be receiving notifications on Telegram or Slack everytime someone enters your server.\n  </p>\n\n    <h3 id=\"credits\">\n      Credits\n    </h3>\n\n  <p>\n    Credits to <a href=\"https://blog.zsec.uk/\" target=\"_blank\" rel=\"nofollow noopener\">ZeroSec</a> for this info.\n  </p>",
            "image": "https://baronhez.github.io/media/posts/12/51-Messages-2.jpg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Self-hosted"
            ],
            "date_published": "2022-08-27T22:38:02+02:00",
            "date_modified": "2022-08-31T01:26:37+02:00"
        },
        {
            "id": "https://baronhez.github.io/how-to-configure-ssh-to-be-secure/",
            "url": "https://baronhez.github.io/how-to-configure-ssh-to-be-secure/",
            "title": "How to install and configure SSH to be secure",
            "summary": "It should&hellip;",
            "content_html": "\n    <h2 id=\"it-should-be-ready-in-just-two-minutes-as-simple-as-that\">\n      It should be ready in just two minutes, as simple as that.\n    </h2>\n\n  <p>\n    I will show you how to configure SSH and make it more secure within a couple of minutes.\n  </p>\n\n    <h3 id=\"connect-to-your-server-using-keys\">\n      Connect to your server using keys\n    </h3>\n\n  <p>\n    First, connect to your server using SSH. Oh, don't you have SSH in your server yet? Ok, then, run these commands in your server:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt-get install openssh-server\nsudo systemctl enable ssh\nsudo systemctl start ssh</code></pre>\n\n  <p>\n    Apt-get doesn't work? Ok, you're not using a debian based distro in your server, so you have to search how to install packages in your distro (it is a 1 minuto google search, I promise).\n  </p>\n\n  <p>\n    Ok, now that SSH is working in our server, connect to the server from another computer, just for testing. If it is working, now run this command in your server (is going to create the directory for the keys and change the permissions of that directory):\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>mkdir ~/.ssh && chmod 700 ~/.ssh</code></pre>\n\n  <p>\n    Now, we have to generate the keys in our computer.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># For Windows:\nssh-keygen -b 4096\n# The keys are stored in \"%userprofile%\\.ssh\" as id_rsa and id_rsa.pub by default.\n#Now, transfer the public key to the server.\nscp $env:USERPROFILE/.ssh/id_rsa.pub Username@123.445.566.233:~/.ssh/authorized_keys    \n# Replace the Username and IP with your own Username and Server IP.\n# For Linux:\nssh-keygen -b 4096\n# The keys are stored in \"~/.ssh\" as id_rsa and id_rsa.pub by default.\n# Now, transfer the public key to the server.\nssh-copy-id Username@123.445.566.233\n# Replace the Username and IP with your own Username and Server IP.\n# For Mac:\nssh-keygen -b 4096\n# The keys are stored in \"~/.ssh\" as id_rsa and id_rsa.pub by default.\n# Now, transfer the public key to the server.\nscp ~/.ssh/id_rsa.pub Username@123.445.566.233:~/.ssh/authorized_keys    \n# Replace the Username and IP with your own Username and Server IP.\n</code></pre>\n\n  <p>\n    Ok, if you connect now to your server through SSH, you will connect directly, without having to input a password. Now, let's continue with the next step.\n  </p>\n\n    <h3 id=\"disable-password-login\">\n      Disable password login\n    </h3>\n\n  <p>\n    Edit the file&nbsp;<i>/etc/ssh/sshd_config </i>using some editor like Nano or Vim. First, search for the <b>KbdInteractiveAuthentication</b> line and change the value to no. This way is not possible to use a keyboard during&nbsp;authentication. Next thing we have to change is&nbsp; <b>PasswordAuthentication</b>. Again, the default value is yes, but we’ll be setting it to no.\n  </p>\n\n  <p class=\"msg msg--info\">\n    Some people may say something like \"Change the ssh port to another one\", but a real hacker (most likely a bot) will scan your ports searching for it, so this act is stupid and annoying without any good reason.\n  </p>\n\n  <p class=\"msg msg--info\">\n    You can also disable root login, but since your user will surely have sudo privileges... well, I leave up to you to decide if it is worth it (I have my root login disable).\n  </p>\n\n    <h3 id=\"remove-weak-prime-numbers\">\n      Remove weak prime numbers\n    </h3>\n\n  <p>\n    The client and the server use these moduli to negotiate a secure key. Remove the small ones by runnings these commands:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>cp /etc/ssh/moduli ~/copy_moduli \nawk '$5 &gt;= 3071' /etc/ssh/moduli &gt; /etc/ssh/moduli.safe\nmv /etc/ssh/moduli.safe /etc/ssh/moduli    </code></pre>\n\n  <p>\n    The first command makes a security copy before changing the moduli in the home folder of your user. The second command looks for lines in /etc/ssh/moduli, which on the fifth line have a value bigger than 3071 and writes those in the moduli.safe file. Then, the third command replace the moduli using the moduli.safe file.\n  </p>\n\n    <h3 id=\"allow-strong-cyphers-only\">\n      Allow strong cyphers only\n    </h3>\n\n  <p>\n    We are going to allow only the most secure cyphers. Create a new file <i>/etc/ssh/sshd_config.d/ssh_hardening.conf</i>. Then, add this content exactly as it is displayed:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256\nCiphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr\nMACs hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,umac-128-etm@openssh.com\nHostKeyAlgorithms ssh-ed25519,ssh-ed25519-cert-v01@openssh.com,sk-ssh-ed25519@openssh.com,sk-ssh-ed25519-cert-v01@openssh.com,rsa-sha2-256,rsa-sha2-512,rsa-sha2-256-cert-v01@openssh.com,rsa-sha2-512-cert-v01@openssh.com  </code></pre>\n\n    <h2 id=\"bonus\">\n      Bonus\n    </h2>\n\n  <p>\n    With all I mention above should be more than enough, the following tips are optional... and will take you more than just a couple of minutes.\n  </p>\n\n    <h3 id=\"usenbspmulti-factor-authentication\">\n      Use&nbsp;Multi Factor Authentication\n    </h3>\n\n  <p>\n    First, update your system:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt update\nsudo apt upgrade -y</code></pre>\n\n  <p>\n    Now, install the&nbsp;<i>libpam-google-authenticator</i> package.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt install libpam-google-authenticator\n</code></pre>\n\n  <p>\n    For MFA, if I'm not mistaken, you will have to enable again the <b>KbdInteractiveAuthentication</b> line in&nbsp;<i>/etc/ssh/sshd_config.</i>\n  </p>\n\n  <p>\n    Once the PAM app is installed you will need to use a helper app that comes with the PAM to generate a Time-Based One-Time Password (TOTP) key for the user you want to add a second factor to. This key is generated on a per user basis, and as a result is not system-wide.&nbsp;To do this simply run:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>google-authenticator</code></pre>\n\n  <p>\n    Upon running the command, you’ll be asked a few questions. The first one asks if authentication tokens should be time-based. We want to select <b>y</b>:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>Do you want authentication tokens to be time-based (y/n): y</code></pre>\n\n  <p>\n    Once we select yes, the app will generate a QR code that can be scanned within your authenticator app of choice.\n  </p>\n\n  <p>\n    This PAM allows for time-based or sequential-based tokens. Using sequential-based tokens mean the code starts at a certain point and then increments the code after every use. Using time-based tokens mean the code changes randomly after a certain time elapses (usually 60s). We’ll stick with time-based because that is what apps like Google Authenticator anticipate.\n  </p>\n\n  <p>\n    The remaining questions inform the PAM how to function. We’ll go through them one by one.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>Do you want me to update your \"/home/zephr/.google_authenticator\" file? (y/n)  </code></pre>\n\n  <p>\n    This writes the key and options to the <b>~/.google_authenticator</b> file. If you select no, then the program will quit and nothing is saved which in turn results in the authenticator application not working. Therefore we want to select <b>yes </b>for this!&nbsp;\n  </p>\n<pre class=\"line-numbers  language-html\"><code>By default, tokens are good for 30 seconds and in order to compensate for\npossible time-skew between the client and the server, we allow an extra\ntoken before and after the current time. If you experience problems with poor\ntime synchronization, you can increase the window from its default\nsize of 1:30min to about 4min. Do you want to do so (y/n) n</code></pre>\n\n  <p>\n    Selecting yes for this question enables up to 8 valid codes in a moving four minute window. By answering no, you limit it to 3 valid codes in a 90 second rolling window.\n  </p>\n\n  <p>\n    Unless you find issues with the 90 second window, answering no is the more secure choice.\n  </p>\n<pre class=\"line-numbers  language-html\"><code>If the computer that you are logging into isn't hardened against brute-force\nlogin attempts, you can enable rate-limiting for the authentication module.\nBy default, this limits attackers to no more than 3 login attempts every 30s.\nDo you want to enable rate-limiting (y/n) y</code></pre>\n\n  <p>\n    Rate limiting means a remote attacker can only attempt a certain number of guesses before being blocked. I recommend you to answer <b>yes</b>.\n  </p>\n\n  <p>\n    Once you finish this setup, if you want to back up your secret key, you can copy the <b>~/.google-authenticator</b> file to a trusted location.&nbsp;\n  </p>\n\n  <p>\n    Once we've been through the steps to configure google authenticator, the next step is to setup our SSH config to allow authenticator to function:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo nano /etc/pam.d/sshd</code></pre>\n\n  <p>\n    Add the following line to the bottom of the file:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># Standard Un*x password updating.\n@include common-password\nauth required pam_google_authenticator.so nullok  </code></pre>\n\n  <p>\n    The <b>nullok</b> word at the end of the last line tells the PAM that this authentication method is optional. This allows users without a OATH-TOTP token to still log in using their SSH key. If you remove <b>nullok</b>&nbsp;from the line, this MFA would be mandatory.\n  </p>\n\n  <p>\n    Next, we’ll configure SSH to support this kind of authentication. Open the SSH configuration file for editing.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo nano /etc/ssh/sshd_config</code></pre>\n\n  <p>\n    &nbsp;We are going to make SSH aware of MFA by adding AuthenticationMethods and UsePAM:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code># To disable tunneled clear text passwords, change to no here!\nPasswordAuthentication no\n#PermitEmptyPasswords no\n\n# Change to yes to enable challenge-response passwords (beware issues with\n# some PAM modules and threads)\n\n\n#ChallengeResponseAuthentication yes\nKbdInteractiveAuthentication yes\nUsePAM yes\nAuthenticationMethods publickey,password publickey,keyboard-interactive</code></pre>\n\n  <p>\n    Save the config and restart the SSH service.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo systemctl reload sshd.service</code></pre>\n\n  <p>\n    Now, you have MFA for your SSH.\n  </p>\n\n    <h3 id=\"enable-firewall-and-make-use-ofnbspratelimiting\">\n      Enable Firewall and make use of&nbsp;Rate-Limiting\n    </h3>\n\n  <p>\n    First, install Uncomplicated Firewall(UFW).\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt install ufw\n</code></pre>\n\n  <p>\n    Now, set a rate limit:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>## ufw limit ssh various usage ##\nufw limit ssh comment 'Rate limit for openssh server'</code></pre>\n\n  <p>\n    When a limit rule is used, ufw will normally allow the connection but will deny connections if an IP address attempts to initiate six or more connections within thirty seconds.\n  </p>\n\n  <p>\n    You can also allow or disallow connections from specific IPs:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>   sudo ufw allow from 1.2.3.4 to any port 22</code></pre>\n\n  <p>\n    The above example only allows connections from 1.2.3.4 to port 22.\n  </p>\n\n    <h3 id=\"set-up-fail2ban\">\n      Set up Fail2Ban\n    </h3>\n\n  <p>\n    We can go a little further by setting up Fail2Ban.&nbsp;Fail2Ban essentially actively looks out for signs of potential password authentication abuses to filter out IP addresses and regularly update the system firewall to suspend these IP addresses for a certain period.\n  </p>\n\n  <p>\n    To install and setup Fail2Ban, run the following commands:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo apt install fail2ban\nsudo cp /etc/fail2ban/jail.{conf,local}\nsudo nano /etc/fail2ban/jail.local</code></pre>\n\n  <p>\n    To configure Fail2Ban, modify the following lines:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>bantime = 1d</code></pre>\n\n  <p>\n    If you assign a negative value, the ban will be permanent.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>findtime = 10m</code></pre>\n\n  <p>\n    <b>findtime</b>&nbsp;defines&nbsp;the time-duration allowed between consecutive login attempts. If the multiple login attempts were made within the time defined by findtime, a ban would be set on the IP.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>maxretry = 5</code></pre>\n\n  <p>\n    <b>maxretry</b>&nbsp;defines&nbsp; the exact number of failed login attempts allowed within the findtime. If the number of failed-authorization attempts within the findtime exceeds the maxretry value, the IP would be banned from logging back in.\n  </p>\n\n  <p>\n    Fail2ban also allows you to grant immunity to IP addresses and IP ranges of your choice.\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>ignoreip = 127.0.0.1/8 ::1 222.222.222.222 192.168.55.0/24</code></pre>\n\n  <p>\n    Upon setting all the options you want, simply start the service then check the status:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>sudo systemctl start fail2ban\nsudo systemctl status fail2ban</code></pre>\n\n    <h2 id=\"credits\">\n      Credits\n    </h2>\n\n  <p>\n    I found all this tweaks and tricks in random sources from internet, but to sum it all, all of them can be found in two webpages, so the credit goes to the authors of <a href=\"https://disknotifier.com/blog/simple-ssh-security/\" target=\"_blank\" class=\"\">https://disknotifier.com/blog/simple-ssh-security/</a> and <a href=\"https://blog.zsec.uk/locking-down-ssh-the-right-way/\" target=\"_blank\">https://blog.zsec.uk/locking-down-ssh-the-right-way</a>/.\n  </p>",
            "image": "https://baronhez.github.io/media/posts/10/ssh-transformed11.jpeg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "SSH"
            ],
            "date_published": "2022-08-27T16:33:26+02:00",
            "date_modified": "2022-08-31T01:26:31+02:00"
        },
        {
            "id": "https://baronhez.github.io/markdown-beginner-guide/",
            "url": "https://baronhez.github.io/markdown-beginner-guide/",
            "title": "Markdown Beginner Guide",
            "summary": "I am&hellip;",
            "content_html": "\n    <h2 id=\"i-am-not-an-expert-but-this-is-more-than-enough-for-me\">\n      I am not an expert, but this is more than enough for me\n    </h2>\n\n  <p>\n    Markdown is more complex than you think, is not only about headings and tables, you can also make complex graphs and even network representations (I'm not joking with this). Today I will share with you, fellow developer, my own beginner guide for Markdown.\n  </p>\n<pre class=\"line-numbers  language-html\"><code># Heading H1\n\n## Heading H2\n\n### Heading H3\n\n#### Heading H4 \n\n##### Heading H5\n\n###### Heading H6\n\nThis is normal text\n\n**This is bold text**\n\n_This is italic text_\n\n*This is also italic text*\n\n- This\n- is\n- an \n- unordened\n- list    \n\n1. This\n2. is\n3. a\n4. list\n1. Ordered \n   1. If you use\n   2. Tab\n      1. It is possible\n      2. to use\n      3. subsections\n         1. really cool\n         \n[This text has a link to www.google.com](www.google.com)\n\n[This text displays an image if you click on it](./path/to/image/example.jpg)\n\n![This alternative text displays an image if you click on it](./path/to/image/example.jpg)\n\n&gt;\"This text is a quote\"\n&gt;\n&gt;-Jonathan  \n\n~~Text through~~\n\nTable:\n\n| Name | Content | Price |\n|------|---------|-------|\n| Name | Content | Price |\n| Name | Content | Price |\n|------|---------|-------|\n|------|---------|-------|\n|------|---------|-------|\n| Name | Content | Price |\n| Name | Content | Price |\n| Name | Content | Price |\n| Name | Content | Price |\n| Name | Content | Price |\n|------|---------|-------|\n|------|---------|-------|\n\nTo put some code, use inline code, like `print(\"Hello, you beaty thing\")`\n\nBut the best practices is to use code snippets, indicating the lenguage:\n\n````java\nint b = a + c;\nsystemprintoutln(b);  \n````\n</code></pre>\n\n  <p>\n    Let's end this with some tricky stuff.\n  </p>\n\n  <p>\n    Take a look into <a href=\"https://mermaid-js.github.io/mermaid/#/\" target=\"_blank\">Mermaid</a>. It allows us to make diagrams and visualizations.\n  </p>\n<pre class=\"line-numbers  language-html\"><code>```mermaid\ngraph LR\n    subgraph Name 1\n    A(internet) --&gt; B[your server]\n    end\n    subgraph Name 2\n    B --&gt; D[whoami1]\n    E[ubuntu test] --&gt; D\n    end\n    subgraph Name 3\n    B --&gt; G[whoami 2]\n    end\n    E-..-&gt; G\n```  \n</code></pre>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://baronhez.github.io/media/posts/8/markdown.PNG\" sizes=\"100vw\" srcset=\"https://baronhez.github.io/media/posts/8/responsive/markdown-xs.PNG 300w ,https://baronhez.github.io/media/posts/8/responsive/markdown-sm.PNG 480w ,https://baronhez.github.io/media/posts/8/responsive/markdown-md.PNG 768w ,https://baronhez.github.io/media/posts/8/responsive/markdown-lg.PNG 1024w ,https://baronhez.github.io/media/posts/8/responsive/markdown-xl.PNG 1360w ,https://baronhez.github.io/media/posts/8/responsive/markdown-2xl.PNG 1600w\"  height=\"392\" width=\"871\" alt=\"\" />\n      <figcaption>This is the final graph. Compare the code snippet with the graph to know how to create this diagram.</figcaption>\n    </figure>\n\n  <p>\n    I recommend you to check mermaid and make more complex diagrams if you work with networks in a daily basis, because it is truly useful for this purpose.&nbsp;\n  </p>\n\n  <p>\n    Thanks for reading my quick guide of Markdown. It is short, but the best things in life are short, and I hate to spend 20 minutes reading the filling of some random article from a guide in the internet about how markdown help some developer to cope with the dead of his lost cousin. Guides should get straight to the point :)\n  </p>",
            "image": "https://baronhez.github.io/media/posts/8/markdown-2.jpg",
            "author": {
                "name": "Jonathan Ródenas López"
            },
            "tags": [
                   "Markdown"
            ],
            "date_published": "2022-08-27T13:14:27+02:00",
            "date_modified": "2022-08-31T01:25:58+02:00"
        }
    ]
}
